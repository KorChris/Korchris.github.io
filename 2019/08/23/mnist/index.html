<!DOCTYPE html>
<html lang=en>
<head>
    <meta charset="utf-8">
    
    <title>[Pytorch]MNIST DNN부터 CNN까지 | Code Brewer</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="MNIST DNN부터 CNN까지Deep Learning을 공부함에 있어서 제일 처음으로 접하는 Data는 바로 MNSIT라고 할 수 있습니다. MNIST는 사람들이 직접 필기로 쓴 숫자로써 0부터 9까지 검은 배경에 하얀 글씨로 쓰여져있는 28 x 28 사이즈의 이미지 데이터입니다. 이 포스팅을 통해서 MNIST 데이터를 Deep Learning을 통해서">
<meta name="keywords" content="Machine Learning,Deep Learning,ML,DL,Pytorch">
<meta property="og:type" content="article">
<meta property="og:title" content="[Pytorch]MNIST DNN부터 CNN까지">
<meta property="og:url" content="http://korchris.github.io/2019/08/23/mnist/index.html">
<meta property="og:site_name" content="Code Brewer">
<meta property="og:description" content="MNIST DNN부터 CNN까지Deep Learning을 공부함에 있어서 제일 처음으로 접하는 Data는 바로 MNSIT라고 할 수 있습니다. MNIST는 사람들이 직접 필기로 쓴 숫자로써 0부터 9까지 검은 배경에 하얀 글씨로 쓰여져있는 28 x 28 사이즈의 이미지 데이터입니다. 이 포스팅을 통해서 MNIST 데이터를 Deep Learning을 통해서">
<meta property="og:locale" content="en">
<meta property="og:image" content="http://korchris.github.io/images/deep_learning.jpg">
<meta property="og:updated_time" content="2020-11-19T10:23:40.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="[Pytorch]MNIST DNN부터 CNN까지">
<meta name="twitter:description" content="MNIST DNN부터 CNN까지Deep Learning을 공부함에 있어서 제일 처음으로 접하는 Data는 바로 MNSIT라고 할 수 있습니다. MNIST는 사람들이 직접 필기로 쓴 숫자로써 0부터 9까지 검은 배경에 하얀 글씨로 쓰여져있는 28 x 28 사이즈의 이미지 데이터입니다. 이 포스팅을 통해서 MNIST 데이터를 Deep Learning을 통해서">
<meta name="twitter:image" content="http://korchris.github.io/images/deep_learning.jpg">
    

    

    

    <link rel="stylesheet" href="/libs/font-awesome5/css/fontawesome.min.css">
    <link rel="stylesheet" href="/libs/font-awesome5/css/fa-brands.min.css">
    <link rel="stylesheet" href="/libs/font-awesome5/css/fa-solid.min.css">
    <link rel="stylesheet" href="/libs/open-sans/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/2.1.3/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
        <script type="text/javascript">
(function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-133241164-1', 'auto');
ga('send', 'pageview');

</script>
    
    
    


</head>

<body>
    <div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">Code Brewer</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/.">Home</a>
                
                    <a class="main-nav-link" href="/about">About</a>
                
                    <a class="main-nav-link" href="/archives">Archives</a>
                
                    <a class="main-nav-link" href="/categories">Categories</a>
                
                    <a class="main-nav-link" href="/tags">Tags</a>
                
            </nav>
            
                
                <nav id="sub-nav">
                    <div class="profile" id="profile-nav">
                        <a id="profile-anchor" href="javascript:;">
                            <img class="avatar" src="/css/images/chanung_jeong.png" />
                            <i class="fas fa-caret-down"></i>
                        </a>
                    </div>
                </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fas fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/.">Home</a></td>
                
                    <td><a class="main-nav-link" href="/about">About</a></td>
                
                    <td><a class="main-nav-link" href="/archives">Archives</a></td>
                
                    <td><a class="main-nav-link" href="/categories">Categories</a></td>
                
                    <td><a class="main-nav-link" href="/tags">Tags</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
                

<aside id="profile" class="profile-fixed">
    <div class="inner profile-inner">
        <div class="base-info profile-block">
            <img id="avatar" src="/css/images/chanung_jeong.png" />
            <h2 id="name">Chanung Jeong</h2>
            <h3 id="title">A.I. Scientist in Standigm.</h3>
            <span id="location"><i class="fas fa-map-marker-alt" style="padding-right: 5px"></i>Seoul, South Korea</span>
            <a id="follow" target="_blank" href="https://github.com/korchris/">FOLLOW</a>
        </div>
        <div class="article-info profile-block">
            <div class="article-info-block">
                8
                <span>posts</span>
            </div>
            <div class="article-info-block">
                21
                <span>tags</span>
            </div>
        </div>
        
        <div class="profile-block social-links">
            <table>
                <tr>
                    
                    
                    <td>
                        <a href="http://github.com/korchris/korchris" target="_blank" title="github" class=tooltip>
                            <i class="fab fa-github"></i>
                        </a>
                    </td>
                    
                </tr>
            </table>
        </div>
        
    </div>
</aside>

            
            <section id="main"><article id="post-mnist" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
            [Pytorch]MNIST DNN부터 CNN까지
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fas fa-calendar-alt"></i>
        <a href="/2019/08/23/mnist/">
            <time datetime="2019-08-23T14:47:00.000Z" itemprop="datePublished">2019-08-23</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fas fa-folder"></i>
        <a class="article-category-link" href="/categories/Machine-Learning/">Machine Learning</a>
    </div>

                        
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/DL/">DL</a>, <a class="tag-link" href="/tags/Deep-Learning/">Deep Learning</a>, <a class="tag-link" href="/tags/ML/">ML</a>, <a class="tag-link" href="/tags/Machine-Learning/">Machine Learning</a>, <a class="tag-link" href="/tags/Pytorch/">Pytorch</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <h1 id="MNIST-DNN부터-CNN까지"><a href="#MNIST-DNN부터-CNN까지" class="headerlink" title="MNIST DNN부터 CNN까지"></a>MNIST DNN부터 CNN까지</h1><p>Deep Learning을 공부함에 있어서 제일 처음으로 접하는 Data는 바로 MNSIT라고 할 수 있습니다. MNIST는 사람들이 직접 필기로 쓴 숫자로써 0부터 9까지 검은 배경에 하얀 글씨로 쓰여져있는 28 x 28 사이즈의 이미지 데이터입니다. 이 포스팅을 통해서 MNIST 데이터를 Deep Learning을 통해서 숫자들을 구별할 수 있는 모델을 설계하고, DNN을 이용한 모델과 CNN을 이용한 모델을 직접 구현해 볼 것입니다.</p>
<h2 id="MNSIT-살펴보기"><a href="#MNSIT-살펴보기" class="headerlink" title="MNSIT 살펴보기"></a>MNSIT 살펴보기</h2><p>MNIST데이터는 다음 그림과 같은 이미지로 구성되어있습니다.<br><img src="/images/overview_mnist.png" alt="overview_mnist"></p>
<p>위에서 설명한 바와 같이 위와 같은 이미지처럼 데이터가 구성되어 있으며, 데이터 하나하나는 다음과 같은 이미지를 구성하고 있습니다.</p>
<p><img src="/images/mnist_sample.jpg" alt="mnist_sample"></p>
<p>Deep Learning 모델이 해야할 일은 input으로써 위와 같은 정보를 받고, 해당 데이터가 0부터 9라는 숫자중에 어떤 숫자인지를 알아맞추는 것입니다. </p>
<p>하지만 이 이미지 파일을 어떻게 Deep learning 모델이 받아들일 수 있도록 할 것인가? 보통 MNIST 데이터는 28 x 28의 숫자를 가진 텐서로 표현이 됩니다. 예를 들어서, 하나의 이미지 파일을 텐서로 표현한 데이터를 출력해보면 다음과 같이 나옵니다. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[...</span><br><span class="line"> <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span></span><br><span class="line"> <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span></span><br><span class="line"> <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span></span><br><span class="line"> <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span></span><br><span class="line"> <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span></span><br><span class="line"> <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span></span><br><span class="line"> <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.01171875</span> <span class="number">0.0703125</span>  <span class="number">0.0703125</span>  <span class="number">0.0703125</span></span><br><span class="line"> <span class="number">0.4921875</span>  <span class="number">0.53125</span>    <span class="number">0.68359375</span> <span class="number">0.1015625</span>  <span class="number">0.6484375</span>  <span class="number">0.99609375</span></span><br><span class="line"> <span class="number">0.96484375</span> <span class="number">0.49609375</span> <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span></span><br><span class="line"> <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span></span><br><span class="line"> <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.1171875</span>  <span class="number">0.140625</span>   <span class="number">0.3671875</span>  <span class="number">0.6015625</span></span><br><span class="line"> <span class="number">0.6640625</span>  <span class="number">0.98828125</span> <span class="number">0.98828125</span> <span class="number">0.98828125</span> <span class="number">0.98828125</span> <span class="number">0.98828125</span></span><br><span class="line"> <span class="number">0.87890625</span> <span class="number">0.671875</span>   <span class="number">0.98828125</span> <span class="number">0.9453125</span>  <span class="number">0.76171875</span> <span class="number">0.25</span></span><br><span class="line"> <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span></span><br><span class="line"> <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.19140625</span></span><br><span class="line"> <span class="number">0.9296875</span>  <span class="number">0.98828125</span> <span class="number">0.98828125</span> <span class="number">0.98828125</span> <span class="number">0.98828125</span> <span class="number">0.98828125</span></span><br><span class="line"> <span class="number">0.98828125</span> <span class="number">0.98828125</span> <span class="number">0.98828125</span> <span class="number">0.98046875</span> <span class="number">0.36328125</span> <span class="number">0.3203125</span></span><br><span class="line"> <span class="number">0.3203125</span>  <span class="number">0.21875</span>    <span class="number">0.15234375</span> <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span></span><br><span class="line"> <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span></span><br><span class="line"> <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.0703125</span>  <span class="number">0.85546875</span> <span class="number">0.98828125</span></span><br><span class="line"> <span class="number">0.98828125</span> <span class="number">0.98828125</span> <span class="number">0.98828125</span> <span class="number">0.98828125</span> <span class="number">0.7734375</span>  <span class="number">0.7109375</span></span><br><span class="line"> <span class="number">0.96484375</span> <span class="number">0.94140625</span> <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span></span><br><span class="line"> <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span></span><br><span class="line"> <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.</span></span><br><span class="line"> <span class="number">0.</span>         <span class="number">0.</span>         <span class="number">0.3125</span>     <span class="number">0.609375</span>   <span class="number">0.41796875</span> <span class="number">0.98828125</span></span><br><span class="line"> <span class="number">0.98828125</span> <span class="number">0.80078125</span> <span class="number">0.04296875</span> <span class="number">0.</span>         <span class="number">0.16796875</span> <span class="number">0.6015</span>]</span><br></pre></td></tr></table></figure>
<p>출력된 값 전부를 표현하기에는 너무 많은 숫자들이기에 약간의 데이터만 포스팅하지만, 간단하게 총 784개의 숫자를 가진 데이터임을 확인할 수 있습니다.(28*28=784)<br>DNN을 이용할 때에는 784의 길이를 가진 형태로 집어넣을 것이고, CNN을 이용할 때에는 28x28을 지닌 그대로의 형태로 집어넣을 것입니다. </p>
<h2 id="MNIST-Practice"><a href="#MNIST-Practice" class="headerlink" title="MNIST Practice"></a>MNIST Practice</h2><p>Pytorch에서 제공하는 기본 MNIST 예제는 CNN으로 이루어져있지만 MNIST는 간단한 데이터이기 때문에, DNN만으로도 충분히 다룰 수 있습니다. 먼저 전체적인 코드를 큰 파트별로 먼저 크게 살펴보고, 그 다음에 하나하나의 파트들을 Line by Line으로 살펴보도록 하겠습니다.</p>
<h3 id="DNN-모델-설계하기"><a href="#DNN-모델-설계하기" class="headerlink" title="DNN 모델 설계하기"></a>DNN 모델 설계하기</h3><p>먼저 Pytorch에서 제공하는 라이브러리를 사용하기 위해 각 라이브러리들을 Import 해주는 작업을 해줍니다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">#Importing Library</span><br><span class="line"></span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">import torch.optim as optim</span><br><span class="line">from torchvision import datasets, transforms</span><br></pre></td></tr></table></figure>
<p>그 다음으로는 DNN을 설계를 할 것인데, 우리가 가진 MNIST데이터는 (1,784)의 데이터 형태를 가지고 있고, 구분하려는 숫자의 종류는 총 10가지라는 것을 생각한 뒤 모델을 설계한다고 생각하면 간단한 DNN은 대략 다음과 같이 구성할 수 있습니다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">#Define Neural Networks Model.</span><br><span class="line"></span><br><span class="line">class Net(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(784, 512)</span><br><span class="line">        self.fc2 = nn.Linear(512, 256)</span><br><span class="line">        self.fc3 = nn.Linear(256, 128)</span><br><span class="line">        self.fc4 = nn.Linear(128, 64)</span><br><span class="line">        self.fc5 = nn.Linear(64, 32)</span><br><span class="line">        self.fc6 = nn.Linear(32, 10)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x = x.float()</span><br><span class="line">        h1 = F.relu(self.fc1(x.view(-1, 784)))</span><br><span class="line">        h2 = F.relu(self.fc2(h1))</span><br><span class="line">        h3 = F.relu(self.fc3(h2))</span><br><span class="line">        h4 = F.relu(self.fc4(h3))</span><br><span class="line">        h5 = F.relu(self.fc5(h4))</span><br><span class="line">        h6 = self.fc6(h5)</span><br><span class="line">        return F.log_softmax(h6, dim=1)</span><br><span class="line"></span><br><span class="line">print(&quot;init model done&quot;)</span><br></pre></td></tr></table></figure>
<p>여러층의 Feed Forward Network를 설계해서, input size는 784, output size는 10이 되도록 설정해줍니다.(input data는 (1, 784)의 형태이고 정답(숫자의 종류)는 총 10가지)</p>
<p>이 다음에는 DNN을 Training시키기 위해 필요한 여러가지 변수들 및 hyper parameter들을 설정해줍니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set Hyper parameters and other variables to train the model.</span></span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">test_batch_size = <span class="number">1000</span></span><br><span class="line">epochs = <span class="number">10</span></span><br><span class="line">lr = <span class="number">0.01</span></span><br><span class="line">momentum = <span class="number">0.5</span></span><br><span class="line">no_cuda = <span class="keyword">True</span></span><br><span class="line">seed = <span class="number">1</span></span><br><span class="line">log_interval = <span class="number">200</span></span><br><span class="line"></span><br><span class="line">use_cuda = <span class="keyword">not</span> no_cuda <span class="keyword">and</span> torch.cuda.is_available()</span><br><span class="line"></span><br><span class="line">torch.manual_seed(seed)</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> use_cuda <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line"></span><br><span class="line">kwargs = &#123;<span class="string">'num_workers'</span>: <span class="number">1</span>, <span class="string">'pin_memory'</span>: <span class="keyword">True</span>&#125; <span class="keyword">if</span> use_cuda <span class="keyword">else</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line">print(<span class="string">"set vars and device done"</span>)</span><br></pre></td></tr></table></figure>
<p>어느정도 필요한 변수들을 선언해줬다면, 그 다음으로는 pytorch의 torchvision이 제공하는 MNIST 데이터들과 데이터들을 읽어올 수 있는 Loader들을 선언해줍니다.<br>그리고 Training을 위한 데이터와 모델의 성능을 평가할 수 있는 Test를 위한 데이터 로더를 선언해줍니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Prepare Data Loader for Training and Validation</span></span><br><span class="line"></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">                 transforms.ToTensor(),</span><br><span class="line">                 transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))])</span><br><span class="line"></span><br><span class="line">train_loader = torch.utils.data.DataLoader(</span><br><span class="line">  datasets.MNIST(<span class="string">'../data'</span>, train=<span class="keyword">True</span>, download=<span class="keyword">True</span>, </span><br><span class="line">                 transform=transform), </span><br><span class="line">    batch_size = batch_size, shuffle=<span class="keyword">True</span>, **kwargs)</span><br><span class="line"></span><br><span class="line">test_loader = torch.utils.data.DataLoader(</span><br><span class="line">        datasets.MNIST(<span class="string">'../data'</span>, train=<span class="keyword">False</span>, download=<span class="keyword">True</span>,</span><br><span class="line">                 transform=transform), </span><br><span class="line">    batch_size=test_batch_size, shuffle=<span class="keyword">True</span>, **kwargs)</span><br></pre></td></tr></table></figure>
<p>위와 같이 Data Loader들을 선언해주셨다면, 그 다음으로는 위에서 우리가 설계했던 DNN 모델을 불러오고, Training에 필요한 Optimizer를 선언해줍니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = Net().to(device)</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)</span><br></pre></td></tr></table></figure>
<p>그 다음으로는 모델을 직접 Training시키는 함수과 Test하는 함수를 구현해줍니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Define Train function and Test function to validate.</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(log_interval, model, device, train_loader, optimizer, epoch)</span>:</span></span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">        data, target = data.to(device), target.to(device)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        output = model(data)</span><br><span class="line">        loss = F.nll_loss(output, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="keyword">if</span> batch_idx % log_interval == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">'Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;'</span>.format(</span><br><span class="line">                epoch, batch_idx * len(data), len(train_loader.dataset),</span><br><span class="line">                <span class="number">100.</span> * batch_idx / len(train_loader), loss.item()))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(log_interval, model, device, test_loader)</span>:</span></span><br><span class="line">    model.eval()</span><br><span class="line">    test_loss = <span class="number">0</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data, target <span class="keyword">in</span> test_loader:</span><br><span class="line">            data, target = data.to(device), target.to(device)</span><br><span class="line">            output = model(data)</span><br><span class="line">            test_loss += F.nll_loss(output, target, reduction=<span class="string">'sum'</span>).item() </span><br><span class="line">            pred = output.argmax(dim=<span class="number">1</span>, keepdim=<span class="keyword">True</span>)</span><br><span class="line">            correct += pred.eq(target.view_as(pred)).sum().item()</span><br><span class="line"></span><br><span class="line">    test_loss /= len(test_loader.dataset)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)\n'</span>.format</span><br><span class="line">          (test_loss, correct, len(test_loader.dataset),</span><br><span class="line">        <span class="number">100.</span> * correct / len(test_loader.dataset)))</span><br></pre></td></tr></table></figure>
<p>Training Data를 한차례 전부 학습에 사용했다면 그것을 하나의 Epoch이라고 부르는데, 모델을 학습시키는데에 하나의 Epoch보다 더 많은 Epoch이 필요하므로 Train과 Test의 과정을 반복하는 반복문을 선언해줍니다. 이 반복문이 끝나면, 마지막으로 Training된 모델을 저장합니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Train and Test the model and save it.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">11</span>):</span><br><span class="line">    train(log_interval, model, device, train_loader, optimizer, epoch)</span><br><span class="line">    test(log_interval, model, device, test_loader)</span><br><span class="line">torch.save(model, <span class="string">'./model.pt'</span>)</span><br></pre></td></tr></table></figure>
<p>여기까지가 Pytorch를 이용해서 DNN으로 MNSIT 데이터들을 분류하는 작업의 코드입니다.</p>
<p>이제는 각 파트별로 소스코드들이 무엇을 의미하는지를 알아보도록 하겠습니다.</p>
<h3 id="DNN-Model"><a href="#DNN-Model" class="headerlink" title="DNN Model."></a>DNN Model.</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">class Net(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(784, 512)</span><br><span class="line">        self.fc2 = nn.Linear(512, 256)</span><br><span class="line">        self.fc3 = nn.Linear(256, 128)</span><br><span class="line">        self.fc4 = nn.Linear(128, 64)</span><br><span class="line">        self.fc5 = nn.Linear(64, 32)</span><br><span class="line">        self.fc6 = nn.Linear(32, 10)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x = x.float()</span><br><span class="line">        h1 = F.relu(self.fc1(x.view(-1, 784)))</span><br><span class="line">        h2 = F.relu(self.fc2(h1))</span><br><span class="line">        h3 = F.relu(self.fc3(h2))</span><br><span class="line">        h4 = F.relu(self.fc4(h3))</span><br><span class="line">        h5 = F.relu(self.fc5(h4))</span><br><span class="line">        h6 = self.fc6(h5)</span><br><span class="line">        return F.log_softmax(h6, dim=1)</span><br></pre></td></tr></table></figure>
<p>위의 DNN 모델은 총 6개의 Linear 레이어를 통해서 학습하게 됩니다. </p>
<p>MNIST data는 간단한 toy data이고, 간단한 데이터이기 때문에 위처럼</p>
<p>단순한 neural networks만으로도 가능합니다.</p>
<p>784 dimension을 가진 MNIST data를 512, 256, 128, … dimension으로</p>
<p>옮겨가며 feature extraction을 할 수 있도록 하며, 각 레이어마다 끝단에는</p>
<p>Relu라는 activation function을 통해 neural network에 nonlinearity를 추가해줍니다. </p>
<p>마지막 단에 Log Softmax를 통해 마지막 레이어를 지난 10개의 값들을 return하는데</p>
<p>Log Softmax의 역할은 마지막 나온 결과값들을 확률로 취급하여 해석하기 위한 하나의 연산입니다.</p>
<h3 id="Hyper-Parameters-and-Variables"><a href="#Hyper-Parameters-and-Variables" class="headerlink" title="Hyper Parameters and Variables"></a>Hyper Parameters and Variables</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">test_batch_size = <span class="number">1000</span></span><br><span class="line">epochs = <span class="number">10</span></span><br><span class="line">lr = <span class="number">0.01</span></span><br><span class="line">momentum = <span class="number">0.5</span></span><br><span class="line">no_cuda = <span class="keyword">True</span></span><br><span class="line">seed = <span class="number">1</span></span><br><span class="line">log_interval = <span class="number">200</span></span><br><span class="line"></span><br><span class="line">use_cuda = <span class="keyword">not</span> no_cuda <span class="keyword">and</span> torch.cuda.is_available()</span><br><span class="line"></span><br><span class="line">torch.manual_seed(seed)</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> use_cuda <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line"></span><br><span class="line">kwargs = &#123;<span class="string">'num_workers'</span>: <span class="number">1</span>, <span class="string">'pin_memory'</span>: <span class="keyword">True</span>&#125; <span class="keyword">if</span> use_cuda <span class="keyword">else</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line">print(<span class="string">"set vars and device done"</span>)</span><br></pre></td></tr></table></figure>
<p>위의 parameter들은 보통 딥러닝 모델을 train할 때, 많이 쓰이는 변수들이며</p>
<p>딥러닝 모델에 큰 영향을 주는 parameter는 hyper parameter라고 합니다.</p>
<p>batch_size란, cpu 혹은 gpu에 한번에 몇개씩의 data를 넣어줄 것인지를 정하는 것입니다. </p>
<p>batch_size의 갯수에 따라서도 딥러닝 모델의 성능이 크게 달라집니다.</p>
<p>epochs같은 경우에는 training data를 1번씩 모두 썼을 때까지를 1 epoch이 지났다고 합니다. </p>
<p>즉, training data가 10개가 있고, 그 data들을 모두 한번씩 training에 썼다면, 1 epoch이 지난 것입니다.</p>
<h3 id="Data-Loader"><a href="#Data-Loader" class="headerlink" title="Data Loader"></a>Data Loader</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Prepare Data Loader for Training and Validation</span></span><br><span class="line"></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">                 transforms.ToTensor(),</span><br><span class="line">                 transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))])</span><br><span class="line"></span><br><span class="line">train_loader = torch.utils.data.DataLoader(</span><br><span class="line">  datasets.MNIST(<span class="string">'../data'</span>, train=<span class="keyword">True</span>, download=<span class="keyword">True</span>, </span><br><span class="line">                 transform=transform), </span><br><span class="line">    batch_size = batch_size, shuffle=<span class="keyword">True</span>, **kwargs)</span><br><span class="line"></span><br><span class="line">test_loader = torch.utils.data.DataLoader(</span><br><span class="line">        datasets.MNIST(<span class="string">'../data'</span>, train=<span class="keyword">False</span>, download=<span class="keyword">True</span>,</span><br><span class="line">                 transform=transform), </span><br><span class="line">    batch_size=test_batch_size, shuffle=<span class="keyword">True</span>, **kwargs)</span><br></pre></td></tr></table></figure>
<p>transform을 통해서 data를 어떻게 처리해줄지 결정을 해줍니다.</p>
<p>함수를 보면, 이미지 데이터를 .ToTensor()를 통해서 tensor형태로 데이터를 변환해준 뒤</p>
<p>Normalize과정을 해주기 위해서 standard deviation와 variation 값을 직접 입력해줍니다. (모든 MNIST이미지를 통해 미리 구해놓은 값입니다.)</p>
<p>그리고 위의 함수에 따라 training set과 test set을 구분해서 만들어줍니다.</p>
<p>현재 torchvision의 함수 자체가 ‘train’이라는 parameter를 통해 training set과 test set을 쉽게 준비할 수 있도록 설계해놨기 때문에, 이를 그대로 사용하시면 됩니다.</p>
<h3 id="Optimizer"><a href="#Optimizer" class="headerlink" title="Optimizer"></a>Optimizer</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = Net().to(device)</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)</span><br></pre></td></tr></table></figure>
<p>Optimizer를 통해서 모델이 어떤 방식으로 training할지를 고르게 됩니다.</p>
<p>대표적인 training방식은 SGD, RMSprop, Adam, AdaDelta 등 여러가지 방식이 있는데</p>
<p>위의 코드는 SGD와 momentum을 사용하는 optimizer를 설정해준 뒤, model내의 parameter들을 training하도록 했습니다.</p>
<h3 id="Train-and-Test"><a href="#Train-and-Test" class="headerlink" title="Train and Test"></a>Train and Test</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Define Train function and Test function to validate.</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(log_interval, model, device, train_loader, optimizer, epoch)</span>:</span></span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">        data, target = data.to(device), target.to(device) <span class="comment"># send data to gpu or cpu</span></span><br><span class="line">        optimizer.zero_grad() <span class="comment"># set gradient zero. </span></span><br><span class="line">        output = model(data) <span class="comment"># get output from model</span></span><br><span class="line">        loss = F.nll_loss(output, target) <span class="comment"># calculate nll loss </span></span><br><span class="line">        loss.backward() <span class="comment"># do backpropagation</span></span><br><span class="line">        optimizer.step() <span class="comment"># update weight and biases</span></span><br><span class="line">        <span class="keyword">if</span> batch_idx % log_interval == <span class="number">0</span>:</span><br><span class="line">            print(<span class="string">'Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;'</span>.format(</span><br><span class="line">                epoch, batch_idx * len(data), len(train_loader.dataset),</span><br><span class="line">                <span class="number">100.</span> * batch_idx / len(train_loader), loss.item()))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">(log_interval, model, device, test_loader)</span>:</span></span><br><span class="line">    model.eval()</span><br><span class="line">    test_loss = <span class="number">0</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data, target <span class="keyword">in</span> test_loader:</span><br><span class="line">            data, target = data.to(device), target.to(device)</span><br><span class="line">            output = model(data)</span><br><span class="line">            test_loss += F.nll_loss(output, target, reduction=<span class="string">'sum'</span>).item() </span><br><span class="line">            pred = output.argmax(dim=<span class="number">1</span>, keepdim=<span class="keyword">True</span>)</span><br><span class="line">            correct += pred.eq(target.view_as(pred)).sum().item()</span><br><span class="line"></span><br><span class="line">    test_loss /= len(test_loader.dataset)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)\n'</span>.format</span><br><span class="line">          (test_loss, correct, len(test_loader.dataset),</span><br><span class="line">        <span class="number">100.</span> * correct / len(test_loader.dataset)))</span><br></pre></td></tr></table></figure>
<p>train함수를 통해서 train data들을 한번씩 살피도록 합니다.</p>
<p>test함수를 통해서 test data를 통해 모델의 성능을 평가하게 됩니다.</p>
<h3 id="Make-machine-works"><a href="#Make-machine-works" class="headerlink" title="Make machine works"></a>Make machine works</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Train and Test the model and save it.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">11</span>):</span><br><span class="line">    train(log_interval, model, device, train_loader, optimizer, epoch)</span><br><span class="line">    test(log_interval, model, device, test_loader)</span><br><span class="line">torch.save(model, <span class="string">'./model.pt'</span>)</span><br></pre></td></tr></table></figure>
<p>train 함수와 test함수를 통해 model을 트레이닝 시키고<br>모든 epoch이 끝나게 되면 torch.save를 통해 모델을 저장시켜줍니다.</p>
<h3 id="CNN-model"><a href="#CNN-model" class="headerlink" title="CNN model"></a>CNN model</h3><p>CNN 모델은 28x28의 MNIST data를 1x784로 고쳐서 쓰는 것이 아닌, 2d data의 형태 그대로 사용하게 됩니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">32</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">        self.dropout1 = nn.Dropout2d(<span class="number">0.25</span>)</span><br><span class="line">        self.dropout2 = nn.Dropout2d(<span class="number">0.5</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">9216</span>, <span class="number">128</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">128</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        x = F.max_pool2d(x, <span class="number">2</span>)</span><br><span class="line">        x = self.dropout1(x)</span><br><span class="line">        x = torch.flatten(x, <span class="number">1</span>)</span><br><span class="line">        x = self.fc1(x)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        x = self.dropout2(x)</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        output = F.log_softmax(x, dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<p>CNN을 이해하기 위해서는 filter size, padding, stride 라는 개념을 알아두셔야 합니다.</p>

        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="http://korchris.github.io/2019/08/23/mnist/" data-id="clvlv8shy000zssi9w48fbzn7" class="article-share-link"><i class="fas fa-share"></i>Share</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fab fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fab fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fab fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fab fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    
        <a href="http://korchris.github.io/2019/08/23/mnist/#comments" class="article-comment-link"><span class="fb-comments-count" data-href="http://korchris.github.io/2019/08/23/mnist/">0</span>&nbsp;Comments</a>
    

        </footer>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2020/03/15/chat_with_chatGPT/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">Newer</strong>
            <div class="article-nav-title">
                
                    chatGPT의 놀라운 대화능력에 대한 실험
                
            </div>
        </a>
    
    
        <a href="/2019/01/25/Alphastar/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">Older</strong>
            <div class="article-nav-title">알파스타,  실시간 전략 게임 스타크래프트2 정복하기[딥마인드 소식 번역]</div>
        </a>
    
</nav>


    
</article>


    
    
        <section id="comments">
    <div class="fb-comments" data-width="100%" data-href="http://korchris.github.io/2019/08/23/mnist/" data-num-posts="5"></div>

</section>
    

</section>
            
                
<aside id="sidebar">
   
        
    <div class="widget-wrap">
        <h3 class="widget-title">recent</h3>
        <div class="widget">
            <ul id="recent-post" class="">
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2021/08/10/M1_chrome_issue/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/M1/">M1</a></p>
                            <p class="item-title"><a href="/2021/08/10/M1_chrome_issue/" class="title">M1 맥북 오류 / 크롬 오류 / 빨간 줄 / 빨간 썸네일 해결 방법</a></p>
                            <p class="item-date"><time datetime="2021-08-09T17:41:00.000Z" itemprop="datePublished">2021-08-10</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2021/04/07/[DL-scratch] 0 - basic python/" class="thumbnail">
    
    
        <span style="background-image:url(/images/DL_scratch/DL_scratch_0_000.jpg)" alt="[DL:scratch] 0 - basic python" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/DEEP-LEARNING/">DEEP LEARNING</a></p>
                            <p class="item-title"><a href="/2021/04/07/[DL-scratch] 0 - basic python/" class="title">[DL:scratch] 0 - basic python</a></p>
                            <p class="item-date"><time datetime="2021-04-07T14:00:00.000Z" itemprop="datePublished">2021-04-07</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2020/03/15/Google_Certificate/" class="thumbnail">
    
    
        <span style="background-image:url(/images/google_certificate.png)" alt="Google Certificate for ML" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Machine-Learning/">Machine Learning</a></p>
                            <p class="item-title"><a href="/2020/03/15/Google_Certificate/" class="title">Google Certificate for ML</a></p>
                            <p class="item-date"><time datetime="2020-03-15T05:22:00.000Z" itemprop="datePublished">2020-03-15</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2020/03/15/chat_with_chatGPT/" class="thumbnail">
    
    
        <span style="background-image:url(/images/chatGPT/chatGPT.png)" alt="chatGPT의 놀라운 대화능력에 대한 실험" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Machine-Learning/">Machine Learning</a></p>
                            <p class="item-title"><a href="/2020/03/15/chat_with_chatGPT/" class="title">chatGPT의 놀라운 대화능력에 대한 실험</a></p>
                            <p class="item-date"><time datetime="2020-03-15T05:22:00.000Z" itemprop="datePublished">2020-03-15</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2019/08/23/mnist/" class="thumbnail">
    
    
        <span style="background-image:url(/images/deep_learning.jpg)" alt="[Pytorch]MNIST DNN부터 CNN까지" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Machine-Learning/">Machine Learning</a></p>
                            <p class="item-title"><a href="/2019/08/23/mnist/" class="title">[Pytorch]MNIST DNN부터 CNN까지</a></p>
                            <p class="item-date"><time datetime="2019-08-23T14:47:00.000Z" itemprop="datePublished">2019-08-23</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">categories</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Blog/">Blog</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Chatbot/">Chatbot</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/DEEP-LEARNING/">DEEP LEARNING</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/M1/">M1</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine Learning</a><span class="category-list-count">4</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">archives</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/08/">August 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/04/">April 2021</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/08/">August 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">June 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">February 2017</a><span class="archive-list-count">1</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">tags</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/AlphaStar/">AlphaStar</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Certificate/">Certificate</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Chrome-issue/">Chrome issue</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Chrome-red-line/">Chrome red line</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Chrome-red-thumbnail/">Chrome red thumbnail</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DL/">DL</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Deep-Learning/">Deep Learning</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Deep-Mind/">Deep Mind</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Deep-learning/">Deep learning</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/M1/">M1</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ML/">ML</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Macbook/">Macbook</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-learning/">Machine learning</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pytorch/">Pytorch</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Reinforcement-learning/">Reinforcement_learning</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tensorflow/">Tensorflow</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/chatbot/">chatbot</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/facebook/">facebook</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hexo/">hexo</a><span class="tag-list-count">1</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">tag cloud</h3>
        <div class="widget tagcloud">
            <a href="/tags/AlphaStar/" style="font-size: 10px;">AlphaStar</a> <a href="/tags/Certificate/" style="font-size: 15px;">Certificate</a> <a href="/tags/Chrome-issue/" style="font-size: 10px;">Chrome issue</a> <a href="/tags/Chrome-red-line/" style="font-size: 10px;">Chrome red line</a> <a href="/tags/Chrome-red-thumbnail/" style="font-size: 10px;">Chrome red thumbnail</a> <a href="/tags/DL/" style="font-size: 15px;">DL</a> <a href="/tags/Deep-Learning/" style="font-size: 20px;">Deep Learning</a> <a href="/tags/Deep-Mind/" style="font-size: 10px;">Deep Mind</a> <a href="/tags/Deep-learning/" style="font-size: 10px;">Deep learning</a> <a href="/tags/M1/" style="font-size: 10px;">M1</a> <a href="/tags/ML/" style="font-size: 15px;">ML</a> <a href="/tags/Macbook/" style="font-size: 10px;">Macbook</a> <a href="/tags/Machine-Learning/" style="font-size: 15px;">Machine Learning</a> <a href="/tags/Machine-learning/" style="font-size: 15px;">Machine learning</a> <a href="/tags/Python/" style="font-size: 10px;">Python</a> <a href="/tags/Pytorch/" style="font-size: 10px;">Pytorch</a> <a href="/tags/Reinforcement-learning/" style="font-size: 10px;">Reinforcement_learning</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/chatbot/" style="font-size: 10px;">chatbot</a> <a href="/tags/facebook/" style="font-size: 10px;">facebook</a> <a href="/tags/hexo/" style="font-size: 10px;">hexo</a>
        </div>
    </div>

    
        
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">links</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://hexo.io">Hexo</a>
                    </li>
                
            </ul>
        </div>
    </div>


    
    <div id="toTop" class="fas fa-angle-up"></div>
</aside>

            
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            &copy; 2024 KorChris<br>
            Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme by <a href="http://github.com/ppoffice">PPOffice</a>
        </div>
    </div>
</footer>
        
    
<script>(function(d, s, id) {
    var js, fjs = d.getElementsByTagName(s)[0];
    if (d.getElementById(id)) return;
    js = d.createElement(s); js.id = id;
    js.src = "//connect.facebook.net/en/sdk.js#xfbml=1&version=v2.8";
    fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>





    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
</body>
</html>